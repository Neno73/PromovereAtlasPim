version: '3.8'

# Coolify Docker Compose Configuration for PromoAtlas PIM
# This file deploys both the Strapi backend and BullMQ workers
#
# Deployment:
# 1. Set all environment variables in Coolify dashboard
# 2. Coolify will inject them into the containers
# 3. Both services use the same codebase with different targets
#
# Services:
# - strapi: Main API server (port 1337)
# - workers: BullMQ workers for background jobs

services:
  # ============================================
  # Strapi Backend API
  # ============================================
  strapi:
    build:
      context: ./backend
      dockerfile: Dockerfile.fixed
      target: production

    container_name: promoatlas-backend
    restart: unless-stopped

    # Environment variables are injected directly by Coolify
    # No env_file needed - Coolify uses the environment: section below

    # Expose Strapi on port 1337
    ports:
      - "1337:1337"

    # Environment variables (injected by Coolify)
    environment:
      # Server Configuration - Force production mode for Docker
      HOST: ${HOST:-0.0.0.0}
      PORT: ${PORT:-1337}
      NODE_ENV: production

      # Strapi Security Keys
      APP_KEYS: ${APP_KEYS}
      API_TOKEN_SALT: ${API_TOKEN_SALT}
      ADMIN_JWT_SECRET: ${ADMIN_JWT_SECRET}
      TRANSFER_TOKEN_SALT: ${TRANSFER_TOKEN_SALT}
      JWT_SECRET: ${JWT_SECRET}

      # Database Configuration (Neon PostgreSQL)
      DATABASE_CLIENT: ${DATABASE_CLIENT:-postgres}
      DATABASE_URL: ${DATABASE_URL}
      DATABASE_HOST: ${DATABASE_HOST}
      DATABASE_PORT: ${DATABASE_PORT:-5432}
      DATABASE_NAME: ${DATABASE_NAME}
      DATABASE_USERNAME: ${DATABASE_USERNAME}
      DATABASE_PASSWORD: ${DATABASE_PASSWORD}
      DATABASE_SSL: ${DATABASE_SSL:-true}
      DATABASE_SCHEMA: ${DATABASE_SCHEMA:-public}

      # Cloudflare R2 Storage
      R2_ACCESS_KEY_ID: ${R2_ACCESS_KEY_ID}
      R2_SECRET_ACCESS_KEY: ${R2_SECRET_ACCESS_KEY}
      R2_BUCKET_NAME: ${R2_BUCKET_NAME}
      R2_ENDPOINT: ${R2_ENDPOINT}
      R2_PUBLIC_URL: ${R2_PUBLIC_URL}

      # Cloudflare Configuration
      CLOUDFLARE_ACCOUNT_ID: ${CLOUDFLARE_ACCOUNT_ID}
      CLOUDFLARE_API_TOKEN: ${CLOUDFLARE_API_TOKEN}
      CLOUDFLARE_RAG_NAME: ${CLOUDFLARE_RAG_NAME}

      # Promidata Integration
      PROMIDATA_BASE_URL: ${PROMIDATA_BASE_URL:-https://promi-dl.de/Profiles/Live/849c892e-b443-4f49-be3a-61a351cbdd23}

      # Redis Configuration (Upstash)
      REDIS_URL: ${REDIS_URL}
      UPSTASH_REDIS_REST_URL: ${UPSTASH_REDIS_REST_URL}
      UPSTASH_REDIS_REST_TOKEN: ${UPSTASH_REDIS_REST_TOKEN}

      # BullMQ Configuration
      BULLMQ_CONCURRENCY_FAMILIES: ${BULLMQ_CONCURRENCY_FAMILIES:-3}
      BULLMQ_CONCURRENCY_IMAGES: ${BULLMQ_CONCURRENCY_IMAGES:-10}
      BULLMQ_JOB_TIMEOUT_SUPPLIER: ${BULLMQ_JOB_TIMEOUT_SUPPLIER:-1800000}
      BULLMQ_JOB_TIMEOUT_FAMILY: ${BULLMQ_JOB_TIMEOUT_FAMILY:-300000}
      BULLMQ_JOB_TIMEOUT_IMAGE: ${BULLMQ_JOB_TIMEOUT_IMAGE:-120000}

    # Health check for Strapi (waits 90s for full startup)
    # Using 127.0.0.1 to avoid IPv6 issues, any HTTP response means server is up
    healthcheck:
      test: ["CMD", "sh", "-c", "wget --quiet --tries=1 --spider --server-response http://127.0.0.1:1337/ 2>&1 | grep -q 'HTTP/'"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 90s

    # Logging configuration
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

    networks:
      - promoatlas

  # ============================================
  # BullMQ Workers - INTEGRATED INTO STRAPI
  # ============================================
  # Workers run automatically inside the Strapi container via src/index.ts bootstrap
  # No separate workers service needed - this prevents "strapi is not defined" errors
  # Workers start when Strapi boots and have full access to Strapi context
  #
  # Worker configuration via environment variables (set in strapi service above):
  # - BULLMQ_CONCURRENCY_FAMILIES: 3 (product family worker parallelism)
  # - BULLMQ_CONCURRENCY_IMAGES: 10 (image upload worker parallelism)
  # - BULLMQ_JOB_TIMEOUT_SUPPLIER: 1800000ms (30 min for supplier sync)
  # - BULLMQ_JOB_TIMEOUT_FAMILY: 300000ms (5 min for product families)
  # - BULLMQ_JOB_TIMEOUT_IMAGE: 120000ms (2 min for image uploads)
  #
  # To scale workers: Increase Coolify replicas - each Strapi instance runs its own workers
  # BullMQ automatically distributes jobs across all worker instances

# ============================================
# Networks
# ============================================
networks:
  promoatlas:
    driver: bridge
    name: promoatlas-network

# ============================================
# Notes:
# ============================================
#
# Deployment in Coolify:
# 1. Application Settings:
#    - Build Pack: Docker Compose
#    - Docker Compose File: docker-compose.coolify.yml
#    - Base Directory: . (root)
#
# 2. Environment Variables:
#    Set all ${VARIABLE} values in Coolify's environment settings.
#    Coolify will inject them during deployment.
#
# 3. Staging vs Production:
#    Create two separate Coolify applications:
#    - "PromoAtlas Staging" (branch: develop)
#    - "PromoAtlas Production" (branch: main)
#
#    Each with different environment variables:
#    - Staging: DATABASE_URL pointing to staging DB
#    - Production: DATABASE_URL pointing to production DB
#
# 4. Monitoring:
#    - Strapi + Worker logs: docker logs promoatlas-backend
#    - Workers start automatically with message: "Started 3 workers: supplier-sync, product-family, image-upload"
#    - Health check: Strapi responds on root endpoint (/)
#
# 5. Scaling:
#    - Increase replicas in Coolify dashboard to scale both API and workers
#    - Each replica runs its own worker set (BullMQ distributes jobs automatically)
#    - Monitor queue performance: Check Redis for job counts and processing times
#
# 6. Troubleshooting:
#    - Check Coolify logs if build fails
#    - Verify all environment variables are set
#    - Ensure Redis is accessible from containers (workers need Redis for BullMQ)
#    - Check logs for worker startup: grep "Started 3 workers" in container logs
#    - If workers don't start: Check REDIS_URL and BullMQ config variables
